{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/williambrunos/Supervised-Machine-Learning-Regression-and-Classification/blob/main/Week_2/gradient_descent_in_practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQC6HUhvfQ6E"
      },
      "source": [
        "# Gradient Descent in Practice\n",
        "\n",
        "Let's take a look at some techiniques that make gradient descent work much better!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcPelZOrfQ6M"
      },
      "source": [
        "## Feature Scaling\n",
        "\n",
        "This technique will allow the gradient descent to work much faster! Let's suppose that the number to be predicted is the price of a house according to the size of it ($x_1$) and the number of bedrooms ($x_2$), according to this expression:\n",
        "\n",
        "$$\\hat{price} = w_1x_1 + w_2x_2 + b$$\n",
        "\n",
        "Let's suppose that the range of values are:\n",
        "\n",
        "- X1:\n",
        "range: 300 - 2,000 -> Large\n",
        "\n",
        "- X2:\n",
        "range: 0 - 5 -> Small range\n",
        "\n",
        "The biggest problem in having features with different range values is that the model will have a large bias tending to assume a lowest weight for the feature with larger range and highest weight for features with lowest range values. This happens in order to normalize the impact of those in the predicted value, but in practice just tends to assume that features have a bigger or lower importance that others just because of their range of values, this is a big problem!\n",
        "\n",
        "And how can we run away from this? Scaling your data, supposing, to a common range of values, for instance [0, 1]. By doing this, the range of value is not going to be important for the model learning and will enhance the algorithm speed.\n",
        "\n",
        "### Mean Normalization\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "gradient_descent_in_practice.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}