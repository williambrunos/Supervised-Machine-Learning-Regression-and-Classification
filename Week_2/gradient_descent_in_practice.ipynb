{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/williambrunos/Supervised-Machine-Learning-Regression-and-Classification/blob/main/Week_2/gradient_descent_in_practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQC6HUhvfQ6E"
      },
      "source": [
        "# Gradient Descent in Practice\n",
        "\n",
        "Let's take a look at some techiniques that make gradient descent work much better!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcPelZOrfQ6M"
      },
      "source": [
        "## Feature Scaling\n",
        "\n",
        "This technique will allow the gradient descent to work much faster! Let's suppose that the number to be predicted is the price of a house according to the size of it ($x_1$) and the number of bedrooms ($x_2$), according to this expression:\n",
        "\n",
        "$$\\hat{price} = w_1x_1 + w_2x_2 + b$$\n",
        "\n",
        "Let's suppose that the range of values are:\n",
        "\n",
        "- X1:\n",
        "range: 300 - 2,000 -> Large\n",
        "\n",
        "- X2:\n",
        "range: 0 - 5 -> Small range\n",
        "\n",
        "The biggest problem in having features with different range values is that the model will have a large bias tending to assume a lowest weight for the feature with larger range and highest weight for features with lowest range values. This happens in order to normalize the impact of those in the predicted value, but in practice just tends to assume that features have a bigger or lower importance that others just because of their range of values, this is a big problem!\n",
        "\n",
        "And how can we run away from this? Scaling your data, supposing, to a common range of values, for instance [0, 1]. By doing this, the range of value is not going to be important for the model learning and will enhance the algorithm speed.\n",
        "\n",
        "### Mean Normalization\n",
        "\n",
        "One way to implement normalization is with **mean normalization**.\n",
        "\n",
        "Suppose that $x_i$ is a feature with minimun and maximun numbers within a certain range of values, $\\mu_i$ its mean. So, the value for this feature after applying the mean normalization will be on range [-1, 1], centereds on 0, using this expression:\n",
        "\n",
        "$$x_{i, normalized} = \\frac{x_i - \\mu_i}{max(x_i) - min(x_i)}$$\n",
        "\n",
        "### Z-Score Normalization \n",
        "\n",
        "An other way to doing normalization is with the **z-score normalization**.\n",
        "\n",
        "At this techinque, we compute the **mean** $\\mu_i$ and the **standard deviation** $\\sigma_i$ for each feature $x_i$ and apply the following calculus:\n",
        "\n",
        "$$x_{i, normalized} = \\frac{x_i - \\mu_i}{\\sigma_i}$$\n",
        "\n",
        "## Checking Gradient Descent for Convergence\n",
        "\n",
        "How can you tell whether the gradient descent is converging to a local minima or not?\n",
        "\n",
        "One way to see this is plotting the **learning curve** of the model, which is a graph showing the decrease values of the cost function J after a certain number of iterations of the algorithm. If a gradient descent is working properly, the learning curve is going to decreasy among the iterations, with it plots a cost function.\n",
        "\n",
        "With this learning curve, you can detect also the **flattened** part of the curve, which is a part where you can call the convergence of the algorithm. One way to find out this, is declaring a certain really short value $\\epsilon = 10^{-3}$, for instance. If the cost function doesn't decreases after one iteration a value larger than $\\epsilon$, then the algorithm can call convergence. \n",
        "\n",
        "**Note**: convergence means that the parameters w and b found are the ones that minimizes the cost function J for the model.\n",
        "\n",
        "## Choosing the Learning Rate\n",
        "\n",
        "How to choose a good value for the learning rate $\\alpha$ for the gradient descent algorithm? If this parameter is to small, it will run very slowly, or it can not even converge if it is too large.\n",
        "\n",
        "### Learning Rate too Large\n",
        "\n",
        "Choosing a value for $\\alpha$ considereed too large cann imply the growing of the cost function J over the iterations, because every step taken by the algorithm will be taken more larger than it could be, difficulting the convergency of the algorithm.\n",
        "\n",
        "### Learning Rate too Small\n",
        "\n",
        "If the learning rate is too small, then the gradient descent algorithm will take too many steps to converge.\n",
        "\n",
        "### Learning Rate Small Enough\n",
        "\n",
        "For a $\\alpha$ parameter chosen as been small enough, the cost function J should decrease on every iteration. \n",
        "\n",
        "If this phenomenon doesn't happen, then you should consider that the code has a bug or the parameter alpha was not chosen properly.\n",
        "\n",
        "## Feature Engineering\n",
        "\n",
        "Choosing and entering the right features on the model is a crucial step to make the algorithm performs well.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "R88_B1zsouF1"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "gradient_descent_in_practice.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}